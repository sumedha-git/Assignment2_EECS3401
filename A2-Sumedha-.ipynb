{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ad233b9",
   "metadata": {},
   "source": [
    "# Because of the UCI ML Repository servers being down, I wasn't able to fully run my code for submission.\n",
    "\n",
    "\n",
    "# Please try running this code during the marking process to see my answers!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a39cbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e44e4ed7",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "1. Importing necessary python libraries to implement the project.\n",
    "2. Importing the adult dataset from ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58d0a02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing major python libraries required for this project\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c74400c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "Error connecting to server",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m     h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[1;32m   1349\u001b[0m               encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:1286\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:1332\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1331\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1332\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendheaders(body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:1281\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_output(message_body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:1041\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(msg)\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1044\u001b[0m \n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:979\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 979\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:1458\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m     server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[0;32m-> 1458\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context\u001b[38;5;241m.\u001b[39mwrap_socket(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock,\n\u001b[1;32m   1459\u001b[0m                                       server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/ssl.py:517\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    512\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    513\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    514\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msslsocket_class\u001b[38;5;241m.\u001b[39m_create(\n\u001b[1;32m    518\u001b[0m         sock\u001b[38;5;241m=\u001b[39msock,\n\u001b[1;32m    519\u001b[0m         server_side\u001b[38;5;241m=\u001b[39mserver_side,\n\u001b[1;32m    520\u001b[0m         do_handshake_on_connect\u001b[38;5;241m=\u001b[39mdo_handshake_on_connect,\n\u001b[1;32m    521\u001b[0m         suppress_ragged_eofs\u001b[38;5;241m=\u001b[39msuppress_ragged_eofs,\n\u001b[1;32m    522\u001b[0m         server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname,\n\u001b[1;32m    523\u001b[0m         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    524\u001b[0m         session\u001b[38;5;241m=\u001b[39msession\n\u001b[1;32m    525\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/ssl.py:1108\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1108\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_handshake()\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/ssl.py:1379\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mdo_handshake()\n\u001b[1;32m   1380\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ucimlrepo/fetch.py:66\u001b[0m, in \u001b[0;36mfetch_ucirepo\u001b[0;34m(name, id)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m     response  \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(api_url)\n\u001b[1;32m     67\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(response)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(req, data)\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_open, protocol, protocol \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    537\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_open\u001b[39m\u001b[38;5;124m'\u001b[39m, req)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    495\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_open(http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mHTTPSConnection, req,\n\u001b[1;32m   1392\u001b[0m         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context, check_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_hostname)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m-> 1351\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[1;32m   1352\u001b[0m r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mucimlrepo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_ucirepo \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# fetch dataset \u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m adult \u001b[38;5;241m=\u001b[39m fetch_ucirepo(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# data (as pandas dataframes) \u001b[39;00m\n\u001b[1;32m      8\u001b[0m X \u001b[38;5;241m=\u001b[39m adult\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfeatures \n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ucimlrepo/fetch.py:69\u001b[0m, in \u001b[0;36mfetch_ucirepo\u001b[0;34m(name, id)\u001b[0m\n\u001b[1;32m     67\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(response)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError, urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mHTTPError):\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError connecting to server\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# verify that dataset exists \u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "\u001b[0;31mConnectionError\u001b[0m: Error connecting to server"
     ]
    }
   ],
   "source": [
    "#importing the adult dataset from ucimlrepo\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "adult = fetch_ucirepo(id=2) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = adult.data.features \n",
    "y = adult.data.targets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1abf33e",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "Taking a quick look at the data structure(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bb4f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking at the first 5 instances in the X dataframe.\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84f4181",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking at major information about the columns of dataframe X\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352ea8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking at the major features of columns containing numerical values in X\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14efd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing the shape of dataframe X\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113a3b4b",
   "metadata": {},
   "source": [
    "## Task 2.1\n",
    "\n",
    "Plotting a histogram of the data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04150242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting a histogram of all numerical features in X\n",
    "X.hist(figsize=(24, 16))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186c9a4e",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "\n",
    "Checking for the number of missing values '?' in X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20c3c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for the number of missing values '?' in X\n",
    "(X == '?').sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20683d09",
   "metadata": {},
   "source": [
    "# Task 4\n",
    "\n",
    "1. Replacing all '?' values in X with null(nan).\n",
    "2. Running a X.info() to see the non-null count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613c2655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing all '?' values in X with null(nan).\n",
    "X = X.replace('?', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b486d080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A X.info() to see the non-null count for all features(columns) in X\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80d84fb",
   "metadata": {},
   "source": [
    "# Task 5\n",
    "\n",
    "Creating and applying a preprocessing pipeline to:\n",
    "1. Fill in the missing numerical values with the mean using a SimpleImputer.\n",
    "2. Scale the numerical columns using StandardScaler (but not the target).\n",
    "3. Fill in the missing categorical values with the most_frequent value using SimpleImputer.\n",
    "4. Encode the categorical columns using OneHotEncoder (but not the target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd73392",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing main functions used for pipelining\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0311cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the cat and num columns\n",
    "# Get a list of column names from the 'X' DataFrame that are of numerical data types.\n",
    "# Get a list of column names from the 'X' DataFrame that are not of numerical data types.\n",
    "\n",
    "num_cols = X.select_dtypes(include='number').columns.to_list()\n",
    "cat_cols = X.select_dtypes(exclude='number').columns.to_list()\n",
    "\n",
    "\n",
    "# Create pipelines for numeric and categorical columns\n",
    "num_pipeline = make_pipeline(SimpleImputer(strategy='mean'), StandardScaler())\n",
    "cat_pipeline = make_pipeline(SimpleImputer(strategy='most_frequent'), OneHotEncoder(sparse_output=False))\n",
    "\n",
    "# Use ColumnTransformer to set the estimators and transformations\n",
    "\n",
    "preprocessing = ColumnTransformer([('num', num_pipeline, num_cols),\n",
    "                                   ('cat', cat_pipeline, cat_cols)],\n",
    "                                    remainder='passthrough'\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ca8023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying the pipeline\n",
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5312ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the preprocessing pipeline on the dataframe X\n",
    "X_prepared = preprocessing.fit_transform(X)\n",
    "\n",
    "\n",
    "# Scikit-learn strips the column headers, so just add them back on afterward.\n",
    "feature_names=preprocessing.get_feature_names_out()\n",
    "X_prepared = pd.DataFrame(data=X_prepared, columns=feature_names)\n",
    "\n",
    "#printing the shape of the newly prepared dataframe\n",
    "X_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004ecbdd",
   "metadata": {},
   "source": [
    "# Task 6\n",
    "\n",
    "Check the target value_counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b41473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the target, ie, y's value_counts\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0534e036",
   "metadata": {},
   "source": [
    "# Task 7\n",
    "\n",
    "Clean the data in the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c795afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning data in the target, ie, y by:\n",
    "\n",
    "#1. replacing all instances of <=50K. in y by <=50K\n",
    "y = y.replace('<=50K.', '<=50K')\n",
    "\n",
    "#2. replacing all instances of >50K. in y by >50K\n",
    "y = y.replace('>50K.', '>50K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50803886",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#displaying the new value_counts for y, after the data cleaning\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e5de5e",
   "metadata": {},
   "source": [
    "# Task 8\n",
    "\n",
    "Splitting the data from the dataframes into a 80% training set, and 20% testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8660224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#assining the new processed and cleaned values from X_prepared to dataframe X\n",
    "X = X_prepared\n",
    "\n",
    "\n",
    "#spitting the X and y dataframes to X_train, X_test, y_train, and y_test respectively and then outputting their shapes.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=57)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc5e121",
   "metadata": {},
   "source": [
    "# Task 9\n",
    "\n",
    "Training a svm model (svc) to predict if the income of the adult exceeds 50K, using the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfebbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "#creating a svm model using poly kernel, C=0.1, and gamma=1\n",
    "model_svm = SVC(kernel='poly', C=0.1, gamma=1) \n",
    "\n",
    "#training the model on the training set\n",
    "model_svm.fit(X_train.iloc[:10000], y_train.iloc[:10000].values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c740973",
   "metadata": {},
   "source": [
    "## Task 9.1\n",
    "\n",
    "Testing model on the X_Test, and reporting the classification_report on the y_test and y_predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d8d354",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing model on the test set\n",
    "y_predict=model_svm.predict(X_test)\n",
    "\n",
    "\n",
    "#Priniting the classification_report on y_test and y_predict\n",
    "print(f'classification_report for C = 1')\n",
    "print (classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0492d7",
   "metadata": {},
   "source": [
    "## Task 9.2\n",
    "\n",
    "Printing the confusion matrix based on the model's prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a550ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing the confusion matrix using y_test and y_predict.\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550dada8",
   "metadata": {},
   "source": [
    "# Task 10\n",
    "\n",
    "Use GridSearchCV to find the best value of kernel, gamma, and C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592472ba",
   "metadata": {},
   "source": [
    "## Task 10.1\n",
    "\n",
    "Splitting the dataset into 60% training, 20% validation, and 20% testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcee98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting X and y into X_train, X_validation_test, y_train, and y_validation_test dataframes respectively, where the size of the training set is 60% of the size and the validation_test is 40%\n",
    "X_train, X_validation_test, y_train, y_validation_test = train_test_split(X_prepared, y, test_size=0.4, random_state=42)\n",
    "\n",
    "\n",
    "#Splitting X_validation_test and y_validation_test into X_validation, X_test, y_validation, and y_test dataframes respectively, where the size of the testing set is 50% of the validation_test set and thus 20% of the whole set, and the same applies for the validation set.\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_validation_test, y_validation_test, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "#printing the shapes of all the newly created dataframes that constitue the training set, the testing set, and the validation set.\n",
    "print(X_train.shape, y_train.shape, X_validation.shape, y_validation.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6863a891",
   "metadata": {},
   "source": [
    "## Task 10.2\n",
    "\n",
    "Finding the best hyperparameters for the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49be0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code author luisguiserrano \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#passing various possible values for hyperparameters C and gamma that would be used for fine-tuning them\n",
    "svm_parameters = {'kernel': ['rbf'],\n",
    "                  'C': [0.01, 0.1, 1 , 10],\n",
    "                  'gamma': [0.01, 1, 10]\n",
    "                }\n",
    "svm = SVC()\n",
    "\n",
    "#using GridSearchCV to find the best value for hyperparameters for C and gamma from the ones we passed before\n",
    "svm_gs = GridSearchCV(estimator = svm,\n",
    "                      param_grid = svm_parameters)\n",
    "svm_gs.fit(X_train.iloc[:10000], y_train.iloc[:10000].values.ravel())\n",
    "\n",
    "svm_winner = svm_gs.best_estimator_\n",
    "\n",
    "\n",
    "#evaluating the accuracy of our model with the fine-tuned hyperparameters\n",
    "svm_winner.score(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23b0773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the values of the fine-tuned hyperparameters\n",
    "svm_winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3758988f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
